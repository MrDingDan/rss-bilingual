<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Bilingual - xgo_931d6e88</title>
    <link>https://github.com/</link>
    <description>Auto translated feed for xgo_931d6e88 (ä¸­æ–‡ + åŸæ–‡)</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 13 Jan 2026 19:47:26 +0000</lastBuildDate>
    <item>
      <title>ç»ˆäºæœ‰æœºä¼šä½“éªŒ@karpathyçš„LLM Councilï¼ˆLLMå§”å‘˜ä¼šï¼‰äº† / Finally got a chance to play around with @karpathy's LLM Council. 

I built it as a plugin inside of...</title>
      <link>https://x.com/omarsar0/status/2009285312531345702</link>
      <description>ç»ˆäºæœ‰æœºä¼šä½“éªŒ@karpathyçš„LLM Councilï¼ˆLLMå§”å‘˜ä¼šï¼‰ã€‚æˆ‘æŠŠå®ƒåšæˆäº†Claude Codeé‡Œçš„ä¸€ä¸ªæ’ä»¶ï¼Œé€šè¿‡OpenRouterè¿æ¥æ¨¡å‹ã€‚AskUserQuestionå·¥å…·å¾ˆæ–¹ä¾¿ï¼Œå¯ä»¥ç”¨æ¥é€‰æ‹©å§”å‘˜ä¼šå’Œä¸»å¸­ã€‚è¿™æ˜¯æˆ‘çš„é¦–æ¬¡æµ‹è¯•ï¼Œä½†æˆ‘åŒæ„Karpathyçš„è§‚ç‚¹ï¼šLLMç»„åˆè¿™ä¸ªæ¦‚å¿µï¼Œä¸ä»…èƒ½ç”¨äºé’ˆå¯¹æœ‰è¶£é—®é¢˜æä¾›ä¸åŒè§†è§’çš„æ¨¡å‹ï¼Œæˆ‘è§‰å¾—å®ƒåœ¨æ™ºèƒ½ä½“ç¼–ç¨‹æ–¹é¢ä¹Ÿä¼šæœ‰å¾ˆé…·çš„åº”ç”¨ã€‚åç»­ä¼šè¯¦ç»†å±•å¼€ã€‚æ—¢ç„¶åšæˆäº†æ’ä»¶ï¼Œæ¥ä¸‹æ¥æˆ‘ä¼šæ¢ç´¢æ™ºèƒ½ä½“ç¼–ç¨‹çš„å…¶ä»–ç”¨ä¾‹ï¼Œæ¯”å¦‚è¯„ä¼°ã€å·¥å…·æ„å»ºã€è®¾è®¡å’Œç ”ç©¶ã€‚å¦‚æœå¤§å®¶æ„Ÿå…´è¶£ï¼Œæˆ‘ä¼šæ•´ç†ä¸€ä¸‹ï¼ŒæŠŠå®ƒå‘å¸ƒæˆâ€¦â€¦

---

Original:
Finally got a chance to play around with @karpathy 's LLM Council. I built it as a plugin inside of Claude Code. Hooked it up with OpenRouter for models. The AskUserQuestion tool came in handy to select the council and chairman. This is my first test, but I agree with Karpathy that the concept of LLM ensembles can be used beyond models that offer perspectives on interesting questions. I feel like this could have really cool applications in agentic coding. More on that soon. I built this as a plugin, so next I will be exploring other user cases around agentic coding, like evaluation, tool building, designing, and research. If there is enough interest, I will clean it up and push it out as anâ€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2009285312531345702</guid>
      <pubDate>Thu, 08 Jan 2026 15:25:23 +0000</pubDate>
    </item>
    <item>
      <title>@karpathy è¿™ç¯‡å…³äºLLMå§”å‘˜ä¼šï¼ˆLLM Councilï¼‰çš„å¸–å­éå¸¸å€¼å¾—ä¸€è¯»ï¼šhttps://t.co/C... / @karpathy Here is @karpathy's post on LLM Council which is a great read for everyone: https://t.co/C...</title>
      <link>https://x.com/omarsar0/status/2009288035028857314</link>
      <description>@karpathy è¿™ç¯‡å…³äºLLMå§”å‘˜ä¼šï¼ˆLLM Councilï¼‰çš„å¸–å­éå¸¸å€¼å¾—ä¸€è¯»ï¼šx.com/karpathy/statuâ€¦ Andrej Karpathy @karpathy ä½œä¸ºä¸€ä¸ªæœ‰è¶£çš„å‘¨å…­æ°›å›´ç¼–ç¨‹é¡¹ç›®ï¼Œä¹Ÿæ˜¯å¯¹æˆ‘æ—©å‰é‚£æ¡æ¨ç‰¹çš„è·Ÿè¿›ï¼Œæˆ‘å¿«é€Ÿæ­å»ºäº†ä¸€ä¸ª**llm-council**ç½‘é¡µåº”ç”¨ã€‚å®ƒçœ‹èµ·æ¥å’ŒChatGPTä¸€æ¨¡ä¸€æ ·ï¼ŒåŒºåˆ«åœ¨äºæ¯ä¸ªç”¨æˆ·æŸ¥è¯¢ä¼šï¼š1) é€šè¿‡OpenRouteråˆ†æ´¾ç»™ä½ å§”å‘˜ä¼šä¸­çš„å¤šä¸ªæ¨¡å‹ï¼Œä¾‹å¦‚ç›®å‰åŒ…æ‹¬ï¼šâ€œopenai/gpt-5.1â€ã€â€œgoogle/gemini-3-pro-previewâ€ã€â€œanthropic/claude-sonnet-4.5â€ã€â€œx-ai/grok-4â€ï¼›ç„¶å2) æ‰€æœ‰æ¨¡å‹éƒ½èƒ½çœ‹åˆ°å½¼æ­¤ï¼ˆåŒ¿ååŒ–ï¼‰çš„å›å¤ï¼Œå¹¶è¿›è¡Œè¯„å®¡å’Œæ’åºï¼›æ¥ç€3) ä¸€ä½â€œä¸»å¸­LLMâ€ä¼šè·å–æ‰€æœ‰è¿™äº›å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå¹¶ç”Ÿæˆæœ€ç»ˆå›å¤ã€‚è§‚å¯Ÿè¿™ä¸ªè¿‡ç¨‹å¾ˆæœ‰è¶£â€¦â€¦

---

Original:
@karpathy Here is @karpathy 's post on LLM Council which is a great read for everyone: x.com/karpathy/statuâ€¦ Andrej Karpathy @karpathy As a fun Saturday vibe code project and following up on this tweet earlier, I hacked up an **llm-council** web app. It looks exactly like ChatGPT except each user query is 1) dispatched to multiple models on your council using OpenRouter, e.g. currently: "openai/gpt-5.1", "google/gemini-3-pro-preview", "anthropic/claude-sonnet-4.5", "x-ai/grok-4", Then 2) all models get to see each other's (anonymized) responses and they review and rank them, and then 3) a "Chairman LLM" gets all of that as context and produces the final response. It's interesting to see theâ€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2009288035028857314</guid>
      <pubDate>Thu, 08 Jan 2026 15:36:12 +0000</pubDate>
    </item>
    <item>
      <title>@karpathy æˆ‘çœ‹åˆ°å¤§ç¥ï¼ˆgoatï¼‰å–œæ¬¢å®ƒã€‚æˆ‘å¯èƒ½å°±æ‰“ç®—è¿™å‡ å¤©å†…å‘å¸ƒã€‚æˆ‘... / @karpathy I see the goat liked it. I might just shoot to publish it in the next couple of days. I wa...</title>
      <link>https://x.com/omarsar0/status/2009357899274047520</link>
      <description>@karpathy æˆ‘çœ‹åˆ°å¤§ç¥ï¼ˆgoatï¼‰å–œæ¬¢å®ƒã€‚æˆ‘å¯èƒ½å°±æ‰“ç®—è¿™å‡ å¤©å†…å‘å¸ƒã€‚æˆ‘æƒ³å†æ¢ç´¢ä¸€ä¸‹å®ƒåœ¨ç¼–ç æ–¹é¢çš„åº”ç”¨åœºæ™¯ï¼Œæ‰€ä»¥ä¼šå¤šèŠ±å‡ å¤©æ—¶é—´ç ”ç©¶ã€‚ğŸ’¬ 0 ğŸ”„ 1 â¤ï¸ 32 ğŸ‘€ 4856 ğŸ“Š 4 âš¡ ç”± xgo.ing é©±åŠ¨

---

Original:
@karpathy I see the goat liked it. I might just shoot to publish it in the next couple of days. I want to explore it a bit for coding use cases, so I will take a few more days to explore. ğŸ’¬ 0 ğŸ”„ 1 â¤ï¸ 32 ğŸ‘€ 4856 ğŸ“Š 4 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2009357899274047520</guid>
      <pubDate>Thu, 08 Jan 2026 20:13:49 +0000</pubDate>
    </item>
    <item>
      <title>LLMæ™ºèƒ½ä½“åœ¨é•¿ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œè¿™æ­£æ˜¯æƒ…å¢ƒå·¥ç¨‹çš„å…³é”®æ‰€åœ¨ã€‚ / LLM agents break down on long tasks.

This is where context engineering really matters.

Agents can ...</title>
      <link>https://x.com/omarsar0/status/2009662975024447511</link>
      <description>LLMæ™ºèƒ½ä½“åœ¨é•¿ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œè¿™æ­£æ˜¯æƒ…å¢ƒå·¥ç¨‹çš„å…³é”®æ‰€åœ¨ã€‚æ™ºèƒ½ä½“èƒ½å¤Ÿæ¨ç†å¹¶ä½¿ç”¨å·¥å…·ï¼Œä½†é•¿æ—¶é—´æ“ä½œä¼šå¯¼è‡´æƒ…å¢ƒæ— é™å¢é•¿å’Œé”™è¯¯ç´¯ç§¯ã€‚å¸¸è§çš„è§£å†³æ–¹æ¡ˆå¦‚æƒ…å¢ƒå‹ç¼©æˆ–æ£€ç´¢å¢å¼ºæç¤ºï¼Œéƒ½å¿…é¡»åœ¨ä¿¡æ¯ä¿çœŸåº¦å’Œæ¨ç†ç¨³å®šæ€§ä¹‹é—´åšå‡ºæƒè¡¡ã€‚è¿™é¡¹æ–°ç ”ç©¶å¼•å…¥äº†InfiAgentæ¡†æ¶ï¼Œæ— è®ºä»»åŠ¡è¿è¡Œå¤šä¹…ï¼Œéƒ½èƒ½ä¸¥æ ¼é™åˆ¶æ™ºèƒ½ä½“çš„æ¨ç†æƒ…å¢ƒã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æŒä¹…çŠ¶æ€å¤–éƒ¨åŒ–ä¸ºä»¥æ–‡ä»¶ä¸ºä¸­å¿ƒçš„æŠ½è±¡ã€‚æ™ºèƒ½ä½“ä¸å†å°†æ‰€æœ‰å†…å®¹å¡å…¥æƒ…å¢ƒï¼Œè€Œæ˜¯ç»´æŠ¤ä¸€ä¸ªè·¨æ­¥éª¤æŒä¹…å­˜åœ¨çš„æ–‡ä»¶å·¥ä½œåŒºã€‚åœ¨æ¯ä¸ªå†³ç­–ç‚¹ï¼Œâ€¦â€¦

---

Original:
LLM agents break down on long tasks. This is where context engineering really matters. Agents can reason and use tools, but extended operations cause unbounded context growth and accumulated errors. Common fixes like context compression or retrieval-augmented prompting force trade-offs between information fidelity and reasoning stability. This new research introduces InfiAgent, a framework that keeps the agent's reasoning context strictly bounded regardless of how long the task runs. The idea is externalize persistent state into a file-centric abstraction. Instead of cramming everything into context, the agent maintains a workspace of files that persist across steps. At each decision point,â€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2009662975024447511</guid>
      <pubDate>Fri, 09 Jan 2026 16:26:05 +0000</pubDate>
    </item>
    <item>
      <title>@elevenlabsio åˆå‘å¸ƒé‡ç£…æ›´æ–°ï¼ / Another huge release from @elevenlabsio!

They just released Scribe v2, which looks like the most ac...</title>
      <link>https://x.com/omarsar0/status/2009684471164113403</link>
      <description>@elevenlabsio åˆå‘å¸ƒé‡ç£…æ›´æ–°ï¼ä»–ä»¬åˆšåˆšæ¨å‡ºäº† Scribe v2ï¼Œçœ‹èµ·æ¥æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å‡†ç¡®çš„è½¬å½•æ¨¡å‹ã€‚è¿™äº›åŸºå‡†æµ‹è¯•ç»“æœä»¤äººç©ç›®ï¼ŒScribe æ ‘ç«‹äº†æ–°çš„å‡†ç¡®åº¦æ ‡å‡†ã€‚ElevenLabs @elevenlabsio ä»Šå¤©ï¼Œæˆ‘ä»¬æ¨å‡º Scribe v2ï¼šè¿™æ˜¯æœ‰å²ä»¥æ¥æœ€å‡†ç¡®çš„è½¬å½•æ¨¡å‹ã€‚Scribe v2 Realtime é’ˆå¯¹è¶…ä½å»¶è¿Ÿå’Œæ™ºèƒ½ä½“ç”¨ä¾‹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œè€Œ Scribe v2 åˆ™ä¸“ä¸ºæ‰¹é‡è½¬å½•ã€å­—å¹•ç”Ÿæˆå’Œå¤§è§„æ¨¡å­—å¹•åˆ¶ä½œè€Œè®¾è®¡ã€‚æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè§†é¢‘æ ‡ç­¾ã€‚ğŸ”— åœ¨ Twitter ä¸ŠæŸ¥çœ‹ ğŸ”— æŸ¥çœ‹å¼•ç”¨æ¨æ–‡ ğŸ’¬ 2 ğŸ”„ 2 â¤ï¸ 37 ğŸ‘€ 9493 ğŸ“Š 7 âš¡ ç”± xgo.ing æä¾›æ”¯æŒ

---

Original:
Another huge release from @elevenlabsio ! They just released Scribe v2, which looks like the most accurate transcription model ever released. Hard to ignore these benchmarks. Scribe sets a new accuracy standard. ElevenLabs @elevenlabsio Today weâ€™re introducing Scribe v2: the most accurate transcription model ever released. While Scribe v2 Realtime is optimized for ultra low latency and agents use cases, Scribe v2 is built for batch transcription, subtitling, and captioning at scale. Your browser does not support the video tag. ğŸ”— View on Twitter ğŸ”— View Quoted Tweet ğŸ’¬ 2 ğŸ”„ 2 â¤ï¸ 37 ğŸ‘€ 9493 ğŸ“Š 7 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2009684471164113403</guid>
      <pubDate>Fri, 09 Jan 2026 17:51:30 +0000</pubDate>
    </item>
    <item>
      <title>Anthropicï¼ˆAnthropicï¼‰åˆä¸€ç¯‡ç²¾å½©å¥½æ–‡ï¼ / Another banger post from Anthropic!

It's all about improving your agents via evals.

Here are my qu...</title>
      <link>https://x.com/omarsar0/status/2009727896706003043</link>
      <description>Anthropicï¼ˆAnthropicï¼‰åˆä¸€ç¯‡ç²¾å½©å¥½æ–‡ï¼ä¸»é¢˜æ˜¯é€šè¿‡è¯„ä¼°æ¥ä¼˜åŒ–ä½ çš„æ™ºèƒ½ä½“ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»åšå®¢ä¸­æç‚¼çš„è¦ç‚¹ï¼šè®©æ™ºèƒ½ä½“å‘æŒ¥ä»·å€¼çš„èƒ½åŠ›ï¼ˆè‡ªä¸»æ€§ã€æ™ºèƒ½ã€çµæ´»æ€§ï¼‰ä¹Ÿæ­£æ˜¯è¯„ä¼°å®ƒä»¬çš„éš¾ç‚¹æ‰€åœ¨ã€‚ä½ ä¸èƒ½ä»…é å•å…ƒæµ‹è¯•å°±æŒ‡æœ›æ™ºèƒ½ä½“åº”ç”¨èƒ½é¡ºåˆ©è¿è¡Œã€‚è¿™ä»½æŒ‡å—è¯¦ç»†æ‹†è§£äº†Anthropicå¼€å‘è€…ç”¨äºæ™ºèƒ½ä½“è¯„ä¼°çš„å®ç”¨æ¡†æ¶ã€‚ä»–ä»¬æåˆ°äº†ä¸‰ç§è¯„ä¼°æ–¹å¼ï¼Œå„æœ‰å–èˆï¼š- åŸºäºä»£ç çš„è¯„ä¼°ï¼šå¿«é€Ÿã€ç»æµã€å¯å¤ç°ï¼Œä½†å¯¹åˆç†å˜åŒ–è¾ƒä¸ºè„†å¼±ã€‚- åŸºäºæ¨¡å‹çš„è¯„ä¼°ï¼šèƒ½å¤„ç†ç»†å¾®å·®åˆ«å’Œå¼€æ”¾å¼ä»»åŠ¡ï¼Œä½†ç»“æœéç¡®å®šæ€§ï¼Œä¸”éœ€äººå·¥æ ¡å‡†ã€‚- äººå·¥è¯„ä¼°æ˜¯é»„é‡‘æ ‡å‡†â€¦â€¦

---

Original:
Another banger post from Anthropic! It's all about improving your agents via evals. Here are my quick takeaways from the blog: The capabilities that make agents useful (autonomy, intelligence, flexibility) are the same ones that make them hard to evaluate. You can't just run unit tests and expect your agentic app to work. This guide breaks down the practical framework Anthropic devs use for agent evals. They mentioned three types of graders, each with trade-offs: - Code-based graders are fast, cheap, and reproducible, but brittle to valid variations. - Model-based graders handle nuance and open-ended tasks, but are non-deterministic and require human calibration. - Human graders are gold-staâ€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2009727896706003043</guid>
      <pubDate>Fri, 09 Jan 2026 20:44:04 +0000</pubDate>
    </item>
    <item>
      <title>MITç ”ç©¶äººå‘˜æå‡ºé€’å½’è¯­è¨€æ¨¡å‹ / MIT researchers propose Recursive Language Models

You are going to hear more on this in 2026.

Why ...</title>
      <link>https://x.com/omarsar0/status/2009988633705742653</link>
      <description>MITç ”ç©¶äººå‘˜æå‡ºé€’å½’è¯­è¨€æ¨¡å‹ï¼Œ2026å¹´å°†æœ‰æ›´å¤šç›¸å…³æ¶ˆæ¯ã€‚ä¸ºä½•é‡è¦ï¼Ÿå¦‚æœå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤„ç†æ¯”å…¶ä¸Šä¸‹æ–‡çª—å£é•¿100å€çš„è¾“å…¥ä¼šæ€æ ·ï¼Ÿä¸Šä¸‹æ–‡é•¿åº¦æ˜¯ä¸€ä¸ªç¡¬æ€§é™åˆ¶ã€‚ä½ å¯ä»¥é€šè¿‡æ¶æ„è°ƒæ•´æ¥æ‰©å±•å®ƒï¼Œä½†æ€»æœ‰é™åº¦ã€‚å¤§å¤šæ•°æ–¹æ³•è¯•å›¾åœ¨çª—å£å†…å¡å…¥æ›´å¤šå†…å®¹æˆ–å‹ç¼©è¶…å‡ºéƒ¨åˆ†ã€‚è¿™é¡¹æ–°ç ”ç©¶é‡‡å–äº†ä¸åŒæ€è·¯ï¼šä¸ç¡¬ç¢°ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œè€Œæ˜¯é€šè¿‡ç¼–ç¨‹æ–¹å¼ç»•è¿‡å®ƒã€‚é€’å½’è¯­è¨€æ¨¡å‹ï¼ˆRLMsï¼‰å°†é•¿æç¤ºè§†ä¸ºå¤–éƒ¨ç¯å¢ƒã€‚æ¨¡å‹å¯ä»¥æ£€æŸ¥æç¤ºï¼Œå°†å…¶åˆ†è§£ä¸ºå¤šä¸ªéƒ¨åˆ†ï¼Œå¹¶åœ¨ç‰‡æ®µä¸Šé€’å½’è°ƒç”¨è‡ªèº«ã€‚è¿™æ˜¯åœ¨æ¨ç†é˜¶æ®µè¿›è¡Œçš„â€¦â€¦

---

Original:
MIT researchers propose Recursive Language Models You are going to hear more on this in 2026. Why does it matter? What if LLMs could process inputs 100x longer than their context window? Context length is a hard constraint. You can extend it with architectural changes, but there's always a limit. Most approaches try to squeeze more into the window or compress what doesn't fit. This new research takes a different approach. Instead of fighting the context limit, work around it programmatically. Recursive Language Models (RLMs) treat long prompts as an external environment. The model can examine the prompt, decompose it into sections, and recursively call itself on snippets. It's inference-timeâ€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2009988633705742653</guid>
      <pubDate>Sat, 10 Jan 2026 14:00:08 +0000</pubDate>
    </item>
    <item>
      <title>è®ºæ–‡ï¼šhttps://t.co/2OUYB1fdxo / Paper: https://t.co/2OUYB1fdxo</title>
      <link>https://x.com/omarsar0/status/2009988651636404377</link>
      <description>è®ºæ–‡ï¼šarxiv.org/abs/2512.24601 ğŸ’¬ 2 ğŸ”„ 1 â¤ï¸ 18 ğŸ‘€ 5232 ğŸ“Š 7 âš¡ ç”± xgo.ing é©±åŠ¨

---

Original:
Paper: arxiv.org/abs/2512.24601 ğŸ’¬ 2 ğŸ”„ 1 â¤ï¸ 18 ğŸ‘€ 5232 ğŸ“Š 7 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2009988651636404377</guid>
      <pubDate>Sat, 10 Jan 2026 14:00:12 +0000</pubDate>
    </item>
    <item>
      <title>ä¸€ç¯‡ä¼˜ç§€è®ºæ–‡å±•ç¤ºäº†æŠ€èƒ½åŠ æŒä¸‹å•æ™ºèƒ½ä½“çš„æ½œåŠ› / Great paper showing how far you can push a single agent with skills.</title>
      <link>https://x.com/omarsar0/status/2010005746075975684</link>
      <description>ä¸€ç¯‡ä¼˜ç§€è®ºæ–‡å±•ç¤ºäº†æŠ€èƒ½åŠ æŒä¸‹å•æ™ºèƒ½ä½“çš„æ½œåŠ›ã€‚DAIR.AI @dair_ai æé—®ï¼šä¸€ä¸ªå…·å¤‡æŠ€èƒ½çš„æ™ºèƒ½ä½“èƒ½å¦æ›¿ä»£å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Ÿå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ“…é•¿å¤æ‚æ¨ç†ï¼Œé€šè¿‡æ˜¾å¼é€šä¿¡å®ç°ä¸“ä¸šæ™ºèƒ½ä½“åä½œï¼Œä½†è¿™ä¼šå¸¦æ¥æ˜¾è‘—çš„ä»¤ç‰Œè®¡ç®—å¼€é”€å’Œå»¶è¿Ÿã€‚è¿™é¡¹æ–°ç ”ç©¶æ¢è®¨äº†æ˜¯å¦å¯ä»¥é€šè¿‡ç”¨æŠ€èƒ½é€‰æ‹©æ›¿ä»£æ™ºèƒ½ä½“é—´é€šä¿¡ï¼Œå°†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç¼–è¯‘ä¸ºç­‰æ•ˆçš„å•æ™ºèƒ½ä½“ç³»ç»Ÿã€‚ç­”æ¡ˆæ˜¯è‚¯å®šçš„ï¼Œä½†æœ‰ä¸ªå‰æã€‚åˆæ­¥å®éªŒè¡¨æ˜ï¼Œé…å¤‡æŠ€èƒ½åº“çš„å•æ™ºèƒ½ä½“æ–¹æ³•èƒ½å¤§å¹…å‡å°‘ä»¤ç‰Œä½¿ç”¨å’Œå»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›â€¦â€¦

---

Original:
Great paper showing how far you can push a single agent with skills. DAIR.AI @dair_ai Can a single agent with skills replace multi-agent systems? Multi-agent systems work well for complex reasoning where specialized agents collaborate through explicit communication. But this incurs substantial computational overhead in tokens and latency. This new research explores whether you can compile a multi-agent system into an equivalent single-agent system by trading inter-agent communication for skill selection. The answer: yes, but with a caveat. Preliminary experiments show single-agent approaches with skill libraries can substantially reduce token usage and latency while maintaining competitive aâ€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2010005746075975684</guid>
      <pubDate>Sat, 10 Jan 2026 15:08:08 +0000</pubDate>
    </item>
    <item>
      <title>ä»‹ç» ralph-research æ’ä»¶ã€‚ / Introducing ralph-research plugin.

I just adopted the ralph-loop for implementing papers. 

Mindblo...</title>
      <link>https://x.com/omarsar0/status/2010359146927763804</link>
      <description>ä»‹ç» ralph-research æ’ä»¶ã€‚æˆ‘åˆšåˆšé‡‡ç”¨ ralph-loop æ¥å®ç°è®ºæ–‡ã€‚æ•ˆæœä¹‹å¥½ä»¤äººæƒŠå¹ã€‚æ•´ä¸ªæ’ä»¶ç”± Claude Code ä¸€æ¬¡æ€§ç”Ÿæˆï¼Œä½†å®ƒå·²ç»èƒ½å¤Ÿç¼–å†™ AI è®ºæ–‡æ¦‚å¿µå¹¶åœ¨è‡ªæˆ‘æ”¹è¿›çš„å¾ªç¯ä¸­è¿è¡Œå®éªŒã€‚å¤ªç–¯ç‹‚äº†ï¼æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè§†é¢‘æ ‡ç­¾ã€‚ğŸ”— åœ¨ Twitter ä¸ŠæŸ¥çœ‹ ğŸ’¬ 50 ğŸ”„ 139 â¤ï¸ 1637 ğŸ‘€ 165343 ğŸ“Š 577 âš¡ ç”± xgo.ing æä¾›æ”¯æŒã€‚

---

Original:
Introducing ralph-research plugin. I just adopted the ralph-loop for implementing papers. Mindblown how good this works already. The entire plugin was one-shotted by Claude Code, but it can already code AI paper concepts and run experiments in a self-improving loop. Wild! Your browser does not support the video tag. ğŸ”— View on Twitter ğŸ’¬ 50 ğŸ”„ 139 â¤ï¸ 1637 ğŸ‘€ 165343 ğŸ“Š 577 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2010359146927763804</guid>
      <pubDate>Sun, 11 Jan 2026 14:32:25 +0000</pubDate>
    </item>
    <item>
      <title>ç¬”è®°ï¼š / Notes:

- It took about 40 minutes to implement the ReAct paper without any interruptions.
- It ran ...</title>
      <link>https://x.com/omarsar0/status/2010359148513280229</link>
      <description>ç¬”è®°ï¼š- åœ¨ä¸é—´æ–­çš„æƒ…å†µä¸‹ï¼Œå®ç°ReActè®ºæ–‡å¤§çº¦èŠ±äº†40åˆ†é’Ÿã€‚- è¿‡ç¨‹ä¸­é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œä½†å®ƒé€æ­¥æ‰¾åˆ°äº†è§£å†³æ–¹æ³•ã€‚è¿™æ­£æ˜¯ralph-loopæå…¶å¼ºå¤§çš„åœ°æ–¹ï¼šå®ƒèƒ½æ¢ç´¢è§£å†³æ–¹æ¡ˆå¹¶ä»é”™è¯¯ä¸­å­¦ä¹ ã€‚æˆ‘è®¤ä¸ºç ”ç©¶å¯èƒ½æ˜¯ralphæ›´ä½³çš„åº”ç”¨åœºæ™¯ï¼Œå› ä¸ºç ”ç©¶éœ€è¦å¤§é‡æ¢ç´¢ã€‚- æˆ‘æµ‹è¯•äº†å…¶ä»–è¾ƒæ–°çš„è®ºæ–‡ï¼Œå®ƒè¡¨ç°è‰¯å¥½ï¼Œè¿™è®©æˆ‘ç›¸ä¿¡å¯ä»¥å°†å…¶å®ç°å¾—æ›´ç¨³å¥ã€‚- æ­£å¦‚è§†é¢‘æ‰€ç¤ºï¼Œä¸ä»»ä½•LLMé©±åŠ¨çš„å·¥å…·ä¸€æ ·ï¼Œå³ä½¿ä½ æä¾›æŒ‡ä»¤å’ŒAPIï¼Œå®ƒä¹Ÿå¯èƒ½éš¾ä»¥ä½¿ç”¨è¾ƒæ–°çš„æ¨¡å‹ã€‚ä½†è¿™æ˜¯câ€¦

---

Original:
Notes: - It took about 40 minutes to implement the ReAct paper without any interruptions. - It ran into some issues, but it figured out how to solve them along the way. This is what makes the ralph-loop extremely powerful. It can explore solutions and learn from its mistakes. I would argue that research is probably an even better use case for ralph as research requires lots of exploration. - I have tested on other newer papers, and it has done a good job, which gives me hope that this could be implemented to be more robust. - As you can see in the video, and as with anything LLM-powered, it will struggle to use newer models even if you give instructions and APIs. But this is something that câ€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2010359148513280229</guid>
      <pubDate>Sun, 11 Jan 2026 14:32:26 +0000</pubDate>
    </item>
    <item>
      <title>åœ¨æœ¬å‘¨çš„ç›´æ’­è¯¾ç¨‹ä¸­ï¼Œæˆ‘å°†åˆ†äº«æ›´å¤šå…³äºåœ¨Claude Codeä¸­å¿«é€Ÿæ„å»ºæ­¤ç±»å·¥å…·çš„è¿‡ç¨‹ / During my live cohort this week, I will share more on my process for quickly building tools like thi...</title>
      <link>https://x.com/omarsar0/status/2010704471408455881</link>
      <description>åœ¨æœ¬å‘¨çš„ç›´æ’­è¯¾ç¨‹ä¸­ï¼Œæˆ‘å°†è¯¦ç»†åˆ†äº«å¦‚ä½•åœ¨Claude Codeï¼ˆdair-ai.thinkific.com/courses/claudeâ€¦ï¼‰ä¸­å¿«é€Ÿæ„å»ºæ­¤ç±»å·¥å…·çš„å·¥ä½œæµç¨‹ã€‚è¿™æ˜¯ä¸€æ¬¡å¼ºåŒ–è®­ç»ƒï¼Œä½†è¿™äº›çŸ¥è¯†åªéœ€å­¦ä¹ ä¸€æ¬¡ï¼Œä¹‹åä¾¿èƒ½åœ¨æ­¤åŸºç¡€ä¸ŠæŒç»­æ„å»ºã€‚ç›®å‰å°šä½™å°‘é‡åé¢ï¼ğŸ’¬ 0 ğŸ”„ 1 â¤ï¸ 13 ğŸ‘€ 4129 ğŸ“Š 3 âš¡ ç”± xgo.ing æä¾›æ”¯æŒ

---

Original:
During my live cohort this week, I will share more on my process for quickly building tools like this in Claude Code: dair-ai.thinkific.com/courses/claudeâ€¦ It's an intensive training, but you only need to learn this stuff once and build from there. There are a few seats left! ğŸ’¬ 0 ğŸ”„ 1 â¤ï¸ 13 ğŸ‘€ 4129 ğŸ“Š 3 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2010704471408455881</guid>
      <pubDate>Mon, 12 Jan 2026 13:24:37 +0000</pubDate>
    </item>
    <item>
      <title>å…³äºæ™ºèƒ½ä½“è®°å¿†ï¼ˆAgentic Memoryï¼‰çš„ç²¾å½©è®ºæ–‡ / Great paper on Agentic Memory.

LLM agents need both long-term and short-term memory to handle compl...</title>
      <link>https://x.com/omarsar0/status/2010712137933730234</link>
      <description>ä¸€ç¯‡å…³äºæ™ºèƒ½ä½“è®°å¿†ï¼ˆAgentic Memoryï¼‰çš„ç²¾å½©è®ºæ–‡ã€‚LLMæ™ºèƒ½ä½“éœ€è¦é•¿æœŸä¸çŸ­æœŸè®°å¿†æ¥å¤„ç†å¤æ‚ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå½“å‰çš„ä¸»æµæ–¹æ³•å°†ä¸¤è€…è§†ä¸ºç‹¬ç«‹ç»„ä»¶ï¼Œå„è‡ªæ‹¥æœ‰å¯å‘è§„åˆ™ã€æ§åˆ¶å™¨å’Œä¼˜åŒ–ç­–ç•¥ã€‚ä½†è®°å¿†å¹¶éä¸¤ä¸ªç‹¬ç«‹ç³»ç»Ÿï¼Œè€Œæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œè´Ÿè´£å†³å®šå­˜å‚¨ã€æ£€ç´¢ã€æ€»ç»“å’Œé—å¿˜çš„å†…å®¹ã€‚è¿™é¡¹æ–°ç ”ç©¶æå‡ºäº†AgeMemæ¡†æ¶ï¼Œé€šè¿‡åŸºäºå·¥å…·çš„æ“ä½œï¼Œå°†é•¿çŸ­æœŸè®°å¿†ç®¡ç†ç»Ÿä¸€æ•´åˆåˆ°æ™ºèƒ½ä½“çš„å†³ç­–ç­–ç•¥ä¸­ã€‚æ™ºèƒ½ä½“ä¸å†ä¾èµ–è§¦å‘å¼è§„åˆ™æˆ–è¾…åŠ©è®°å¿†ç®¡ç†å™¨ï¼Œè€Œæ˜¯è‡ªä¸»å­¦ä¼šä½•æ—¶åŠå¦‚ä½•è°ƒç”¨è®°å¿†æ“ä½œï¼šå¦‚æ·»åŠ ï¼ˆADDï¼‰ã€æ›´æ–°ï¼ˆUPDï¼‰ç­‰ã€‚

---

Original:
Great paper on Agentic Memory. LLM agents need both long-term and short-term memory to handle complex tasks. However, the default approach today treats these as separate components, each with its own heuristics, controllers, and optimization strategies. But memory isn't two independent systems. It's one cognitive process that decides what to store, retrieve, summarize, and forget. This new research introduces AgeMem, a unified framework that integrates long-term and short-term memory management directly into the agent's policy through tool-based actions. Instead of relying on trigger-based rules or auxiliary memory managers, the agent learns when and how to invoke memory operations: ADD, UPDâ€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2010712137933730234</guid>
      <pubDate>Mon, 12 Jan 2026 13:55:05 +0000</pubDate>
    </item>
    <item>
      <title>Claude Code åŠ©ä½ å®Œæˆå‰©ä½™å·¥ä½œ / Claude Code for the rest of your work.

I was already doing this by building little apps using Claud...</title>
      <link>https://x.com/omarsar0/status/2010811386058654207</link>
      <description>Claude Code åŠ©ä½ å®Œæˆå‰©ä½™å·¥ä½œã€‚æˆ‘æ­¤å‰å·²é€šè¿‡ Claude Agent SDK æ„å»ºå°å‹åº”ç”¨æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼Œç°åœ¨å®ƒå˜å¾—æ›´åŠ ç®€å•ã€‚Claudeï¼ˆ@claudeaiï¼‰æ¨å‡º Coworkï¼šClaude Code åŠ©ä½ å®Œæˆå‰©ä½™å·¥ä½œã€‚Cowork è®©ä½ èƒ½å¤Ÿå®ŒæˆéæŠ€æœ¯æ€§ä»»åŠ¡ï¼Œå…¶æ–¹å¼ç±»ä¼¼äºå¼€å‘è€…ä½¿ç”¨ Claude Codeã€‚ä½ çš„æµè§ˆå™¨ä¸æ”¯æŒè§†é¢‘æ ‡ç­¾ã€‚ğŸ”— åœ¨ Twitter ä¸ŠæŸ¥çœ‹ ğŸ”— æŸ¥çœ‹å¼•ç”¨æ¨æ–‡ ğŸ’¬ 6 ğŸ”„ 1 â¤ï¸ 62 ğŸ‘€ 8214 ğŸ“Š 11 âš¡ ç”± xgo.ing æä¾›æ”¯æŒ

---

Original:
Claude Code for the rest of your work. I was already doing this by building little apps using Claude Agent SDK. It now gets even easier. Claude @claudeai Introducing Cowork: Claude Code for the rest of your work. Cowork lets you complete non-technical tasks much like how developers use Claude Code. Your browser does not support the video tag. ğŸ”— View on Twitter ğŸ”— View Quoted Tweet ğŸ’¬ 6 ğŸ”„ 1 â¤ï¸ 62 ğŸ‘€ 8214 ğŸ“Š 11 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2010811386058654207</guid>
      <pubDate>Mon, 12 Jan 2026 20:29:28 +0000</pubDate>
    </item>
    <item>
      <title>åˆ«é”™è¿‡Claude Agent SDKï¼Œå¿«å»ç”¨å®ƒæ„å»ºç‚¹ä»€ä¹ˆå§ã€‚ / Don't miss out on Claude Agent SDK. Go try to build something with it. Use Claude Code to help you o...</title>
      <link>https://x.com/omarsar0/status/2010822422488887492</link>
      <description>åˆ«é”™è¿‡Claude Agent SDKï¼Œå¿«å»ç”¨å®ƒæ„å»ºç‚¹ä»€ä¹ˆå§ã€‚åˆšå¼€å§‹æ—¶ï¼Œå¯ä»¥ç”¨Claude Codeæ¥å¸®ä½ ã€‚æœ‰ä¸ªä¸é”™çš„æ’ä»¶å¯ç”¨ï¼Œèƒ½åŠ©ä½ å¿«é€Ÿä¸Šæ‰‹ã€‚å€ŸåŠ©Claude Codeçš„å¼ºå¤§åŠŸèƒ½ï¼Œä½ å¯ä»¥æ‰“é€ è‡ªå·±çš„ä¸ªäººåŠ©æ‰‹ï¼Œå°±åƒCoworkä¸€æ ·ã€‚ğŸ’¬ 0 ğŸ”„ 0 â¤ï¸ 4 ğŸ‘€ 1858 ğŸ“Š 1 âš¡ ç”±xgo.ingé©±åŠ¨

---

Original:
Don't miss out on Claude Agent SDK. Go try to build something with it. Use Claude Code to help you out as you start. There is a nice plugin available to get building. You can build your own personal assistant with the power of Claude Code, just like Cowork. ğŸ’¬ 0 ğŸ”„ 0 â¤ï¸ 4 ğŸ‘€ 1858 ğŸ“Š 1 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2010822422488887492</guid>
      <pubDate>Mon, 12 Jan 2026 21:13:19 +0000</pubDate>
    </item>
    <item>
      <title>Metaä¸åˆä½œä¼™ä¼´å‘å¸ƒæ–°ç ”ç©¶ / New research from Meta and collaborators.

This is a good paper showing what's possible with proper ...</title>
      <link>https://x.com/omarsar0/status/2011076284164542639</link>
      <description>Metaä¸åˆä½œä¼™ä¼´å‘å¸ƒæ–°ç ”ç©¶ã€‚è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†é€šè¿‡æ°å½“çš„ä¸–ç•Œæ¨¡å‹å¯ä»¥å®ç°ä»€ä¹ˆã€‚ä¸–ç•Œæ¨¡å‹éœ€è¦åŠ¨ä½œæ¥é¢„æµ‹ç»“æœã€‚å½“å‰çš„ä¸»æµæ–¹æ³•éœ€è¦æ ‡æ³¨çš„åŠ¨ä½œæ•°æ®ï¼Œè·å–æˆæœ¬é«˜æ˜‚ï¼Œä¸”ä»…é™äºè§†é¢‘æ¸¸æˆæˆ–æœºå™¨äººæ“ä½œç­‰ç‹­çª„é¢†åŸŸã€‚ä½†ç»å¤§å¤šæ•°åœ¨çº¿è§†é¢‘æ•°æ®æ ¹æœ¬æ²¡æœ‰åŠ¨ä½œæ ‡ç­¾ã€‚è¿™é¡¹æ–°ç ”ç©¶è‡´åŠ›äºç›´æ¥ä»é‡ç”Ÿè§†é¢‘ä¸­å­¦ä¹ æ½œåœ¨åŠ¨ä½œä¸–ç•Œæ¨¡å‹ï¼Œçªç ´äº†ä»¥å¾€å—æ§ç¯å¢ƒçš„é™åˆ¶ï¼Œä»¥æ•æ‰ç°å®ä¸–ç•ŒåŠ¨ä½œçš„å®Œæ•´å¤šæ ·æ€§ã€‚æŒ‘æˆ˜æ˜¯å·¨å¤§çš„ã€‚é‡ç”Ÿè§†é¢‘ä¸­çš„åŠ¨ä½œè¿œä¸æ­¢ç®€å•çš„å¯¼èˆªæˆ–æ“ä½œâ€¦â€¦

---

Original:
New research from Meta and collaborators. This is a good paper showing what's possible with proper world models. World models need actions to predict consequences. The default approach today requires labeled action data, which is expensive to obtain and limited to narrow domains like video games or robotic manipulation. But the vast majority of video data online has no action labels at all. This new research tackles learning latent action world models directly from in-the-wild videos, expanding beyond the controlled settings of previous work to capture the full diversity of real-world actions. The challenge is significant. In-the-wild videos contain actions far beyond simple navigation or maâ€¦</description>
      <guid isPermaLink="false">xgo-931d6e88::2011076284164542639</guid>
      <pubDate>Tue, 13 Jan 2026 14:02:04 +0000</pubDate>
    </item>
    <item>
      <title>æˆ‘ä¸ºAnthropicï¼ˆAnthropicï¼‰æŒç»­ä¼˜åŒ–Claude Codeçš„æ˜“ç”¨æ€§ç‚¹èµã€‚ / I applaud Anthropic for relentlessly making Claude Code easier to use.

You can now leverage modes w...</title>
      <link>https://x.com/omarsar0/status/2011111792877973851</link>
      <description>æˆ‘ä¸ºAnthropicï¼ˆAnthropicï¼‰æŒç»­ä¼˜åŒ–Claude Codeçš„æ˜“ç”¨æ€§ç‚¹èµã€‚ç°åœ¨ï¼Œä½ å¯ä»¥åœ¨Claude Desktopçš„Codeæ¨¡å¼ä¸­çµæ´»è¿ç”¨è¿™äº›åŠŸèƒ½ã€‚æé—®ã€è§„åˆ’å’Œæ‰§è¡Œæ˜¯è®©æ™ºèƒ½ä½“é«˜æ•ˆè¿ä½œçš„å…³é”®ç¯èŠ‚ï¼Œå¦‚ä»Šåªéœ€ä¸€é”®å³å¯è½»æ¾è°ƒç”¨ã€‚ğŸ’¬ 6 ğŸ”„ 2 â¤ï¸ 38 ğŸ‘€ 3087 ğŸ“Š 11 âš¡ ç”±xgo.ingé©±åŠ¨

---

Original:
I applaud Anthropic for relentlessly making Claude Code easier to use. You can now leverage modes within Code in Claude Desktop. Ask, Plan, and Execute are some of the most important components to make an agent work. And they are now available at the press of a button. ğŸ’¬ 6 ğŸ”„ 2 â¤ï¸ 38 ğŸ‘€ 3087 ğŸ“Š 11 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2011111792877973851</guid>
      <pubDate>Tue, 13 Jan 2026 16:23:10 +0000</pubDate>
    </item>
    <item>
      <title>è¿™äº›åŠŸèƒ½åœ¨Coworkä¸­åŒæ ·å…·å¤‡ã€‚æˆ‘ä¾ç„¶åçˆ±é€šè¿‡ç»ˆç«¯ä½¿ç”¨Claude Codeï¼Œä½†è¿™èƒ½è®©æ›´å¤šéæŠ€æœ¯èƒŒæ™¯çš„äººå‚ä¸è¿›æ¥ã€‚ / These features are also in Cowork.
I still prefer to use Claude Code via the terminal, but this is g...</title>
      <link>https://x.com/omarsar0/status/2011112571504373851</link>
      <description>è¿™äº›åŠŸèƒ½åœ¨Coworkä¸­åŒæ ·å…·å¤‡ã€‚æˆ‘ä¾ç„¶åçˆ±é€šè¿‡ç»ˆç«¯ä½¿ç”¨Claude Codeï¼Œä½†è¿™èƒ½è®©æ›´å¤šéæŠ€æœ¯èƒŒæ™¯çš„äººå‚ä¸è¿›æ¥ã€‚è¿™æ­¥æ£‹å¾ˆæ˜æ™ºï¼Œå› ä¸ºå›¢é˜Ÿç°åœ¨å¯ä»¥æ ¹æ®è‡ªå·±çš„ä¹ æƒ¯é€‰æ‹©ä»»æ„ç‰ˆæœ¬çš„Claude Codeã€‚ğŸ’¬ 1 ğŸ”„ 0 â¤ï¸ 5 ğŸ‘€ 1333 ğŸ“Š 1 âš¡ ç”± xgo.ing é©±åŠ¨

---

Original:
These features are also in Cowork. I still prefer to use Claude Code via the terminal, but this is going to allow more folks with non-technical backgrounds get in the action. Smart move because teams can now use whatever flavor of Claude Code they feel comfortable with. ğŸ’¬ 1 ğŸ”„ 0 â¤ï¸ 5 ğŸ‘€ 1333 ğŸ“Š 1 âš¡ Powered by xgo.ing</description>
      <guid isPermaLink="false">xgo-931d6e88::2011112571504373851</guid>
      <pubDate>Tue, 13 Jan 2026 16:26:16 +0000</pubDate>
    </item>
  </channel>
</rss>
